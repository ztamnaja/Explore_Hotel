{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "\n",
    "import random\n",
    "from fp.fp import FreeProxy\n",
    "from fake_useragent import UserAgent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIP(rand=True, anonym=True):\n",
    "    ua = UserAgent()\n",
    "    proxy = FreeProxy( rand=rand, anonym=anonym).get()\n",
    "    ip = proxy.split(\"://\")[1]\n",
    "    return ua.random, ip\n",
    "\n",
    "def initDriver(rotated_proxy=False):\n",
    "    # setting webdriver selenium -- aviod bot detected\n",
    "    option = webdriver.ChromeOptions()\n",
    "    # Removes navigator.webdriver flagIngest\n",
    "    option.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    option.add_experimental_option('useAutomationExtension', False)\n",
    "\n",
    "    option.add_argument('--disable-blink-features=AutomationControlled')\n",
    "    option.add_argument(\"window-size=1280,800\")\n",
    "    \n",
    "    if rotated_proxy == True: # if false = have prox\n",
    "        print('rotated proxy')\n",
    "        # NOTE: comment when not want to use\n",
    "        userAgent, proxyIP = getIP()\n",
    "        print('proxy =', proxyIP)\n",
    "        option.add_argument(f'proxy-server={proxyIP}')\n",
    "        option.add_argument(f'user-agent={userAgent}')\n",
    "        \n",
    "    return webdriver.Chrome(executable_path='chromedriver.exe', options=option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hotel_list():\n",
    "  url = 'https://www.tripadvisor.com/Hotels-g28932-Hawaii-Hotels.html'\n",
    "  driver = initDriver(rotated_proxy=False)\n",
    "  driver.get(url) # open driver to \n",
    "  # click see all\n",
    "  see_all_button = driver.find_element(\"xpath\", '/html/body/div[2]/div[1]/div[2]/div/div[2]/div[3]/div[2]/div[9]/div/div/button')  # new version\n",
    "  see_all_button.click()\n",
    "\n",
    "  import bs4\n",
    "  # change markup lang string html to object{} \n",
    "  data = driver.page_source\n",
    "  soup = bs4.BeautifulSoup(data,\"html.parser\")\n",
    "  hotels_list_tag = soup.find(\"div\", {\"id\": 'map_wc_dusty_bridge'}).find_all('div')[1]\n",
    "  hotels_list_30 = hotels_list_tag.attrs['data-hotels-data']\n",
    "  hotels_list_30 = json.loads(hotels_list_30)\n",
    "  hotels_list_30['geoName'] = 'Hawaii'\n",
    "\n",
    "\n",
    "  return hotels_list_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- call function to get list top 30 hotels of Hawaii ----\n",
    "# hotels_list_30 =  get_hotel_list()\n",
    "\n",
    "# # save file json\n",
    "  # with open('./data/Hawaii_hotel_list_30.json', 'w') as fp:\n",
    "  #   json.dump(hotels_list_30, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load data from json\n",
    "# with open('./data/Hawaii_hotel_list_30.json', 'r') as fp:\n",
    "#   hotels_list_30 = json.load(fp)\n",
    "  \n",
    "# hotels_list_30 = hotels_list_30['hotels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "\n",
    "def get_reviews(url, num_page=3):\n",
    "    # import the webdriver\n",
    "    driver = initDriver()\n",
    "    driver.get(url)\n",
    "\n",
    "    # change the value inside the range to save more or less reviews\n",
    "    review_list = []\n",
    "    page = 0\n",
    "    for i in range(0, num_page):\n",
    "        page +=1 \n",
    "        print(f'page [{page}/{num_page}]')           \n",
    "        \n",
    "        time.sleep(1)\n",
    "        # driver.find_element(By.XPATH,\".//div[contains(@data-test-target, 'expand-review')]\").click()\n",
    "        # expand the review\n",
    "        try:\n",
    "            WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \".//div[contains(@data-test-target, 'expand-review')]\"))).click()\n",
    "        except StaleElementReferenceException:\n",
    "            WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \".//div[contains(@data-test-target, 'expand-review')]\"))).click()\n",
    "        except TimeoutException:\n",
    "            driver.refresh()\n",
    "            time.sleep(2)\n",
    "            WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \".//div[contains(@data-test-target, 'expand-review')]\"))).click()\n",
    "            continue \n",
    "        \n",
    "        # while True:\n",
    "        #     element = WebDriverWait(driver, 30).until(EC.element_to_be_clickable((By.XPATH, \".//div[contains(@data-test-target, 'expand-review')]\")))\n",
    "        #     if element != None:\n",
    "        #         element.click()\n",
    "        #         break\n",
    "        #     else:\n",
    "        #         driver.refresh()\n",
    "        #         time.sleep(2)\n",
    "        #         continue \n",
    "    \n",
    "        \n",
    "        container = driver.find_elements(By.XPATH,\"//div[@data-reviewid]\")\n",
    "        dates = driver.find_elements(By.XPATH,\".//div[@class='sCZGP']\")\n",
    "\n",
    "        for j in range(len(container)):\n",
    "            data_reviewid = container[j].get_attribute('data-reviewid') \n",
    "            # print('data_reviewid:',data_reviewid)\n",
    "            rating = container[j].find_element(By.XPATH,\".//span[contains(@class, 'ui_bubble_rating bubble_')]\").get_attribute(\"class\").split(\"_\")[3]\n",
    "            title = container[j].find_element(By.XPATH,\".//div[@class='KgQgP MC _S b S6 H5 _a']\").text\n",
    "            review = container[j].find_element(By.XPATH,\".//div[@class='fIrGe _T']\").text.replace('\\n','  ')\n",
    "            review_date = dates[j].text.split('wrote a review')[1].split('\\n')[0].strip()\n",
    "            \n",
    "            try:\n",
    "                origin = dates[j].find_element(By.XPATH,\".//span[contains(@class, 'default LXUOn small')]\").text\n",
    "            except NoSuchElementException:\n",
    "                origin = None\n",
    "            try:\n",
    "                stay_date = container[j].find_element(By.XPATH,\".//span[contains(@class, 'teHYY _R Me S4 H3')]\").text.split(':')[1].strip()\n",
    "            except NoSuchElementException:\n",
    "                stay_date = None\n",
    "            try:\n",
    "                trip_type = container[j].find_element(By.XPATH,\".//span[contains(@class, 'TDKzw _R Me')]\").text.split(':')[1].strip()\n",
    "                # trip_type = container[j].find_element(By.XPATH,\".//span[contains(@class, 'TDKzw _R Me')]\").text\n",
    "            except NoSuchElementException:\n",
    "                trip_type = None\n",
    "            try:\n",
    "                room_tip = container[j].find_element(By.XPATH,\".//div[@class='Pb']\").text.split(':')[1].strip()\n",
    "            except NoSuchElementException:\n",
    "                room_tip = None\n",
    "                \n",
    "            review_list.append([data_reviewid,rating,title,review,review_date,stay_date,trip_type,room_tip,origin])\n",
    "\n",
    "        # change the page, note: not found in last page\n",
    "        try:\n",
    "            driver.find_element(By.XPATH,'.//a[@class=\"ui_button nav next primary \"]').click()\n",
    "        except NoSuchElementException:\n",
    "            break\n",
    "\n",
    "    driver.quit()\n",
    "    columnName = ['reviewid','rating','title','review','review_date','stay_date','trip_type','room_tip','origin']\n",
    "    return pd.DataFrame(data=review_list, columns=columnName) # df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop all hotel_list and thier numReviews\n",
    "with open('./data/Hawaii_hotel_list_30.json', 'r') as fp:\n",
    "  hotels_list_30 = json.load(fp)\n",
    "\n",
    "base_url = 'https://www.tripadvisor.com'  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling for test (run one url)\n",
    "idx = 0 # see in _hotel_list.json\n",
    "\n",
    "hotel_name = hotels_list_30[\"geoName\"]\n",
    "url = base_url + hotels_list_30[idx]['detailUrl']\n",
    "num_page = round(hotels_list_30[idx]['numReviews'] / 10)\n",
    "hotel_id = hotels_list_30[idx][\"id\"]\n",
    "df = get_reviews(url,num_page)\n",
    "df.to_csv(f'./data/{hotel_name}_{hotel_id}.csv',  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop all hotel_list and thier numReviews\n",
    "with open('./data/Hawaii_hotel_list_30.json', 'r') as fp:\n",
    "  hotels_list_30 = json.load(fp)\n",
    "\n",
    "base_url = 'https://www.tripadvisor.com'  \n",
    "\n",
    "\n",
    "for hotel in hotels_list_30['hotels']:\n",
    "  # print(hotel['numReviews'])\n",
    "  url = base_url + hotel['detailUrl']\n",
    "  total_page = round(hotel['numReviews'] / 10)\n",
    "  hotel_id = hotel[\"id\"]\n",
    "  print(f'...scraping url:{url}')\n",
    "  df = get_reviews(url, total_page)\n",
    "  df.to_csv(f'./data/{hotels_list_30[\"geoName\"]}_{hotel[\"id\"]}.csv',  index=False)\n",
    "  # reviews = pd.concat([reviews, df], axis=0) # mock total_page: not send this param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backup code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-69-80ef26bf8993>:25: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  return webdriver.Chrome(executable_path='chromedriver.exe', options=option)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 862596585\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewid</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>review_date</th>\n",
       "      <th>stay_date</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862596585</td>\n",
       "      <td>20</td>\n",
       "      <td>It is pretty unimpressed so far</td>\n",
       "      <td>I read other reviews and didn’t believe. So fa...</td>\n",
       "      <td>Sep 2022</td>\n",
       "      <td>September 2022</td>\n",
       "      <td>Traveled with family</td>\n",
       "      <td>West Orange, New Jersey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>808709695</td>\n",
       "      <td>50</td>\n",
       "      <td>Excellent stay at the village</td>\n",
       "      <td>We stayed one night in the rainbow tower full ...</td>\n",
       "      <td>Sep 2021</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>Traveled with family</td>\n",
       "      <td>Queens Village, New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>862587824</td>\n",
       "      <td>40</td>\n",
       "      <td>Worth it if you do your homework</td>\n",
       "      <td>Fourth time in Waikiki but first time at the H...</td>\n",
       "      <td>Sep 2022</td>\n",
       "      <td>September 2022</td>\n",
       "      <td>None</td>\n",
       "      <td>Glasgow, United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>862547086</td>\n",
       "      <td>20</td>\n",
       "      <td>Never again. Outdated and overpriced.</td>\n",
       "      <td>We stayed in Sept 2022 for 6 nights. . After a...</td>\n",
       "      <td>Sep 2022</td>\n",
       "      <td>September 2022</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>862393047</td>\n",
       "      <td>30</td>\n",
       "      <td>Overpriced and outdated</td>\n",
       "      <td>Over priced &amp; outdated. Was placed in one of t...</td>\n",
       "      <td>Sep 2022</td>\n",
       "      <td>September 2022</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>862351021</td>\n",
       "      <td>30</td>\n",
       "      <td>Not as expected.</td>\n",
       "      <td>LOTS of people...more than I expected. Our sal...</td>\n",
       "      <td>Sep 2022</td>\n",
       "      <td>September 2022</td>\n",
       "      <td>Traveled with family</td>\n",
       "      <td>Crescent City, California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>862126697</td>\n",
       "      <td>10</td>\n",
       "      <td>Stay away</td>\n",
       "      <td>Sold the prepaid room to someone else. Put us ...</td>\n",
       "      <td>Sep 2022</td>\n",
       "      <td>September 2022</td>\n",
       "      <td>Traveled with family</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>861949142</td>\n",
       "      <td>30</td>\n",
       "      <td>Disappointed</td>\n",
       "      <td>Hotel was a total disappointment. We were urge...</td>\n",
       "      <td>Sep 2022</td>\n",
       "      <td>September 2022</td>\n",
       "      <td>Traveled with friends</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>861885025</td>\n",
       "      <td>20</td>\n",
       "      <td>disappointed dinner</td>\n",
       "      <td>place was beautiful so waa view. Service was l...</td>\n",
       "      <td>Sep 2022</td>\n",
       "      <td>September 2022</td>\n",
       "      <td>Traveled as a couple</td>\n",
       "      <td>Brewster, New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>861562040</td>\n",
       "      <td>40</td>\n",
       "      <td>Aloha Spirit</td>\n",
       "      <td>Hilton Hawaiian Village is a beautiful hotel, ...</td>\n",
       "      <td>Sep 2022</td>\n",
       "      <td>September 2022</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    reviewid rating                                  title  \\\n",
       "0  862596585     20        It is pretty unimpressed so far   \n",
       "1  808709695     50          Excellent stay at the village   \n",
       "2  862587824     40       Worth it if you do your homework   \n",
       "3  862547086     20  Never again. Outdated and overpriced.   \n",
       "4  862393047     30                Overpriced and outdated   \n",
       "5  862351021     30                       Not as expected.   \n",
       "6  862126697     10                              Stay away   \n",
       "7  861949142     30                           Disappointed   \n",
       "8  861885025     20                    disappointed dinner   \n",
       "9  861562040     40                           Aloha Spirit   \n",
       "\n",
       "                                              review review_date  \\\n",
       "0  I read other reviews and didn’t believe. So fa...    Sep 2022   \n",
       "1  We stayed one night in the rainbow tower full ...    Sep 2021   \n",
       "2  Fourth time in Waikiki but first time at the H...    Sep 2022   \n",
       "3  We stayed in Sept 2022 for 6 nights. . After a...    Sep 2022   \n",
       "4  Over priced & outdated. Was placed in one of t...    Sep 2022   \n",
       "5  LOTS of people...more than I expected. Our sal...    Sep 2022   \n",
       "6  Sold the prepaid room to someone else. Put us ...    Sep 2022   \n",
       "7  Hotel was a total disappointment. We were urge...    Sep 2022   \n",
       "8  place was beautiful so waa view. Service was l...    Sep 2022   \n",
       "9  Hilton Hawaiian Village is a beautiful hotel, ...    Sep 2022   \n",
       "\n",
       "        stay_date              trip_type                     origin  \n",
       "0  September 2022   Traveled with family    West Orange, New Jersey  \n",
       "1     August 2021   Traveled with family   Queens Village, New York  \n",
       "2  September 2022                   None    Glasgow, United Kingdom  \n",
       "3  September 2022                   None                       None  \n",
       "4  September 2022                   None                       None  \n",
       "5  September 2022   Traveled with family  Crescent City, California  \n",
       "6  September 2022   Traveled with family                       None  \n",
       "7  September 2022  Traveled with friends                       None  \n",
       "8  September 2022   Traveled as a couple         Brewster, New York  \n",
       "9  September 2022                   None                       None  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# import sys\n",
    "# import csv\n",
    "# import time\n",
    "# from selenium import webdriver\n",
    "# from selenium.common.exceptions import NoSuchElementException\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.support.ui import WebDriverWait \n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "# # default path to file to store data\n",
    "# path_to_file = \"/Users/gius/Desktop/reviews.csv\"\n",
    "\n",
    "# # default number of scraped pages\n",
    "# num_page = 1\n",
    "\n",
    "# url = 'https://www.tripadvisor.com/Hotel_Review-g60982-d87016-Reviews-Hilton_Hawaiian_Village_Waikiki_Beach_Resort-Honolulu_Oahu_Hawaii.html'\n",
    "\n",
    "# # import the webdriver\n",
    "# driver = initDriver()\n",
    "# driver.get(url)\n",
    "# driver.find_element(By.XPATH,\".//div[contains(@data-test-target, 'expand-review')]\").click()\n",
    "\n",
    "# review_list = []\n",
    "# container = driver.find_elements(By.XPATH,\"//div[@data-reviewid]\")\n",
    "# dates = driver.find_elements(By.XPATH,\".//div[@class='sCZGP']\")\n",
    "# # print('container',container)\n",
    "# print('id',container[0].get_attribute('data-reviewid'))\n",
    "# for j in range(len(container)):\n",
    "#     data_reviewid = container[j].get_attribute('data-reviewid') \n",
    "#     rating = container[j].find_element(By.XPATH,\".//span[contains(@class, 'ui_bubble_rating bubble_')]\").get_attribute(\"class\").split(\"_\")[3]\n",
    "#     title = container[j].find_element(By.XPATH,\".//div[@class='KgQgP MC _S b S6 H5 _a']\").text\n",
    "#     review = container[j].find_element(By.XPATH,\".//div[@class='fIrGe _T']\").text\n",
    "#     reviewDate = dates[j].text.split('wrote a review')[1].split('\\n')[0].strip()\n",
    "    \n",
    "#     try:\n",
    "#         origin = dates[j].find_element(By.XPATH,\".//span[contains(@class, 'default LXUOn small')]\").text\n",
    "#     except NoSuchElementException:\n",
    "#         origin = None\n",
    "#     try:\n",
    "#         stayDate = container[j].find_element(By.XPATH,\".//span[contains(@class, 'teHYY _R Me S4 H3')]\").text.split(':')[1].strip()\n",
    "#     except NoSuchElementException:\n",
    "#         stayDate = None\n",
    "#     try:\n",
    "#         tripType = container[j].find_element(By.XPATH,\".//span[contains(@class, 'TDKzw _R Me')]\").text.split(':')[1].strip()\n",
    "#     except NoSuchElementException:\n",
    "#         tripType = None\n",
    "    \n",
    "#     review_list.append([data_reviewid,rating,title,review,reviewDate,stayDate,tripType,origin])\n",
    "    \n",
    "# #     # print('title:',title)\n",
    "# #     # print('review_date:',review_date)\n",
    "# #     # print('stay_date:',stay_date)\n",
    "# #     # print('origin:',origin)\n",
    "\n",
    "# #     # df['rating'] = rating\n",
    "# #     # df['title'] = title\n",
    "# #     # df['review'] = review\n",
    "# #     # df['review_date'] = reviewDate\n",
    "# #     # df['stay_date'] = stayDate\n",
    "# #     # df['trip_type'] = tripType\n",
    "\n",
    "\n",
    "# # # # # change the page            \n",
    "# # # # driver.find_element(By.XPATH,'.//a[@class=\"ui_button nav next primary \"]').click()\n",
    "# # # # driver.quit()\n",
    "# columnName = ['reviewid','rating','title','review','review_date','stay_date','trip_type','origin']\n",
    "# df = pd.DataFrame(data=review_list, columns=columnName)\n",
    "# df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "763b8da4a79ad11e4f32e866ced499328a337549e2659251c34b52d077063d81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
